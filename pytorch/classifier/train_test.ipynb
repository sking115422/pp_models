{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import gc\n",
    "import os\n",
    "import numpy as np\n",
    "import shutil\n",
    "import random\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_curve, auc, confusion_matrix\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dir = \"/mnt/nis_lab_research/data/class_data/far_shah_b1-b3\"\n",
    "out_dir = \"../../data/classifier/far_shah_b1-b3\"\n",
    "num_workers = 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize to the input size expected by ResNet\n",
    "    transforms.ToTensor(),\n",
    "    # CHANGE TO BE DATA SPECIFIC\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tt_split(input_dir, out_dir, train_ratio):\n",
    "    \"\"\"\n",
    "    Splits the dataset in the given directory into train and test sets.\n",
    "\n",
    "    :param input_dir: Path to the input directory.\n",
    "    :param train_ratio: Ratio of train set (between 0 and 1).\n",
    "    \"\"\"\n",
    "    if not 0 <= train_ratio <= 1:\n",
    "        raise ValueError(\"Train ratio must be between 0 and 1\")\n",
    "\n",
    "    base_dir = out_dir\n",
    "    train_dir = os.path.join(base_dir, 'train')\n",
    "    test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "    # Create train and test directories\n",
    "    for directory in [train_dir, test_dir]:\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "    # Process each class directory\n",
    "    for class_name in os.listdir(input_dir):\n",
    "        class_dir = os.path.join(input_dir, class_name)\n",
    "        if os.path.isdir(class_dir):\n",
    "            # Create class directories in train and test\n",
    "            os.makedirs(os.path.join(train_dir, class_name), exist_ok=True)\n",
    "            os.makedirs(os.path.join(test_dir, class_name), exist_ok=True)\n",
    "\n",
    "            # Get a list of images and shuffle them\n",
    "            images = os.listdir(class_dir)\n",
    "            random.shuffle(images)\n",
    "\n",
    "            # Split images into train and test\n",
    "            split_point = int(len(images) * train_ratio)\n",
    "            train_images = images[:split_point]\n",
    "            test_images = images[split_point:]\n",
    "\n",
    "            # Copy images to train and test directories\n",
    "            for image in train_images:\n",
    "                shutil.copy2(os.path.join(class_dir, image), os.path.join(train_dir, class_name))\n",
    "            for image in test_images:\n",
    "                shutil.copy2(os.path.join(class_dir, image), os.path.join(test_dir, class_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_split(in_dir, out_dir, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.ImageFolder(root='../../data/classifier/far_shah-b1-b2_cln/train', transform=transform)\n",
    "train_loader = DataLoader(train_set, batch_size=128, shuffle=True, num_workers=num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = torchvision.datasets.ImageFolder(root='../../data/classifier/far_shah-b1-b2_cln/test', transform=transform)\n",
    "test_loader = DataLoader(test_set, batch_size=128, shuffle=True, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, 26)  # 27 total classes - text captcha have 0 so it is removed for now\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(0, 25):  # loop over the dataset multiple times\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        print(i)\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss / len(train_loader)}\")\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can be saved directly from the GPU\n",
    "torch.save(model, './pth/test_ep25.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load the model later\n",
    "model = torch.load('./pth/far_shah_b1-b3_rn50_ep25.pth')\n",
    "model.eval()  # Set it to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Variables to hold predictions and actual labels\n",
    "y_pred = []\n",
    "y_true = []\n",
    "y_score = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        probabilities = torch.softmax(outputs, dim=1)  # Assuming outputs are raw scores from your model\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        # Accumulate true labels and predictions\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_score.extend(probabilities.cpu().numpy())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert accumulated predictions and labels to numpy arrays\n",
    "y_pred = np.array(y_pred)\n",
    "y_true = np.array(y_true)\n",
    "y_score = np.array(y_score)\n",
    "\n",
    "# Determine the unique classes in y_true and binarize\n",
    "classes = np.unique(y_true)  # Identify unique class labels\n",
    "y_true_binarized = label_binarize(y_true, classes=classes)\n",
    "\n",
    "n_classes = len(classes)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = np.mean(y_pred == y_true)\n",
    "precision = precision_score(y_true, y_pred, average=\"weighted\", labels=classes)\n",
    "recall = recall_score(y_true, y_pred, average=\"weighted\", labels=classes)\n",
    "f1 = f1_score(y_true, y_pred, average=\"weighted\", labels=classes)\n",
    "\n",
    "# ROC Curve and AUC for Micro-average\n",
    "fpr, tpr, _ = roc_curve(y_true_binarized.ravel(), y_score.ravel())\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Print metrics\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}')\n",
    "\n",
    "# Calculate and visualize the confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred, labels=classes)\n",
    "plt.figure(figsize=(12, 12))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.show()\n",
    "\n",
    "# Plot ROC Curve for Micro-average\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=lw, label='Micro-average ROC curve (area = {0:0.2f})'.format(roc_auc))\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic - Micro-average')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_class_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
