{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import gc\n",
    "import os\n",
    "import numpy as np\n",
    "import shutil\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dir = \"/mnt/nis_lab_research/data/class_data/far_shah-b1-b2_cln\"\n",
    "out_dir = \"../../data/classifier/far_shah-b1-b2_cln\"\n",
    "num_workers = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize to the input size expected by ResNet\n",
    "    transforms.ToTensor(),\n",
    "    # CHANGE TO BE DATA SPECIFIC\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tt_split(input_dir, out_dir, train_ratio):\n",
    "    \"\"\"\n",
    "    Splits the dataset in the given directory into train and test sets.\n",
    "\n",
    "    :param input_dir: Path to the input directory.\n",
    "    :param train_ratio: Ratio of train set (between 0 and 1).\n",
    "    \"\"\"\n",
    "    if not 0 <= train_ratio <= 1:\n",
    "        raise ValueError(\"Train ratio must be between 0 and 1\")\n",
    "\n",
    "    base_dir = out_dir\n",
    "    train_dir = os.path.join(base_dir, 'train')\n",
    "    test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "    # Create train and test directories\n",
    "    for directory in [train_dir, test_dir]:\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "    # Process each class directory\n",
    "    for class_name in os.listdir(input_dir):\n",
    "        class_dir = os.path.join(input_dir, class_name)\n",
    "        if os.path.isdir(class_dir):\n",
    "            # Create class directories in train and test\n",
    "            os.makedirs(os.path.join(train_dir, class_name), exist_ok=True)\n",
    "            os.makedirs(os.path.join(test_dir, class_name), exist_ok=True)\n",
    "\n",
    "            # Get a list of images and shuffle them\n",
    "            images = os.listdir(class_dir)\n",
    "            random.shuffle(images)\n",
    "\n",
    "            # Split images into train and test\n",
    "            split_point = int(len(images) * train_ratio)\n",
    "            train_images = images[:split_point]\n",
    "            test_images = images[split_point:]\n",
    "\n",
    "            # Copy images to train and test directories\n",
    "            for image in train_images:\n",
    "                shutil.copy2(os.path.join(class_dir, image), os.path.join(train_dir, class_name))\n",
    "            for image in test_images:\n",
    "                shutil.copy2(os.path.join(class_dir, image), os.path.join(test_dir, class_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_split(in_dir, out_dir, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.ImageFolder(root='../../data/classifier/far_shah-b1-b2_cln/train', transform=transform)\n",
    "train_loader = DataLoader(train_set, batch_size=128, shuffle=True, num_workers=num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = torchvision.datasets.ImageFolder(root='../../data/classifier/far_shah-b1-b2_cln/test', transform=transform)\n",
    "test_loader = DataLoader(test_set, batch_size=128, shuffle=True, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, 26)  # 27 total classes - text captcha have 0 so it is removed for now\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(0, 3):  # loop over the dataset multiple times\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        print(i)\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss / len(train_loader)}\")\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can be saved directly from the GPU\n",
    "torch.save(model, './pth/far_shah-b1-b2_cln_pretrained_ep3.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # To load the model later\n",
    "# model = torch.load('./pth/class_test_cd_ep3.pth')\n",
    "# model.eval()  # Set it to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:  # Assuming test_loader is your DataLoader for test data\n",
    "        images, labels = images.to(device), labels.to(device)  # Move to device if using GPU\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy of the model on the test images: {accuracy}%')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_class_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
