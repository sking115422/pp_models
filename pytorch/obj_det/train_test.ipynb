{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection Model For Pixel Prowler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import copy\n",
    "import random\n",
    "import string\n",
    "import io\n",
    "import sys\n",
    "import cv2\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "from pycocotools.coco import COCO\n",
    "import torchvision.models as models\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.backbone_utils import resnet_fpn_backbone\n",
    "from torchvision.ops import sigmoid_focal_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "in_dir = \"/mnt/nis_lab_research/data/coco_files/eoi/far_shah_b1-b3_EOI\"\n",
    "data_dir = os.path.join(\"../../data/obj_det\", os.path.basename(in_dir))\n",
    "rand_str = ''.join(random.choices(string.ascii_letters + string.digits, k=6))\n",
    "res_name = os.path.basename(in_dir) + \"_\" + rand_str\n",
    "out_dir = os.path.join(\"./out\", res_name)\n",
    "os.makedirs(out_dir)\n",
    "num_test_imgs_out = 100\n",
    "\n",
    "cuda_device_num = [1]\n",
    "\n",
    "batch_size = 8  \n",
    "num_workers = 8 \n",
    "shuffle = True\n",
    "img_height = 1080\n",
    "img_width = 1920\n",
    "\n",
    "num_classes = 1 + 1\n",
    "num_epochs = 25\n",
    "backbone = \"resnet50\"\n",
    "pretrained = False\n",
    "optimizer = \"Adam\"\n",
    "learning_rate = 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CocoDetection(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, annFile, transform=None):\n",
    "        self.root = root\n",
    "        self.coco = COCO(annFile)\n",
    "        self.ids = list(sorted(self.coco.imgs.keys()))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        coco = self.coco\n",
    "        img_id = self.ids[index]\n",
    "        ann_ids = coco.getAnnIds(imgIds=img_id)\n",
    "        annotations = coco.loadAnns(ann_ids)\n",
    "\n",
    "        path = coco.loadImgs(img_id)[0]['file_name']\n",
    "        img = Image.open(os.path.join(self.root, path)).convert('RGB')\n",
    "\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        img_ids = []\n",
    "        for ann in annotations:\n",
    "            # Convert COCO bbox format (x_min, y_min, width, height) to (x_min, y_min, x_max, y_max)\n",
    "            x, y, w, h = ann['bbox']\n",
    "            x_max = x + w\n",
    "            y_max = y + h\n",
    "\n",
    "            # Check if the bounding box is valid (positive width and height)\n",
    "            if w > 0 and h > 0:\n",
    "                boxes.append([x, y, x_max, y_max])\n",
    "                labels.append(ann['category_id'])\n",
    "                img_ids.append(img_id)\n",
    "\n",
    "        if len(boxes) == 0:\n",
    "            boxes = torch.zeros((0, 4), dtype=torch.float32)\n",
    "            labels = torch.zeros((0,), dtype=torch.int64)\n",
    "            img_ids.append(img_id)\n",
    "        else:\n",
    "            boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "            labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "            img_ids.append(img_id)\n",
    "\n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"img_ids\"] = img_ids\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to set the device\n",
    "def set_device(cuda_device_num):\n",
    "    # Check if CUDA is available\n",
    "    if torch.cuda.is_available():\n",
    "        num_devices = torch.cuda.device_count()\n",
    "        print(f\"Number of CUDA devices available: {num_devices}\")\n",
    "        \n",
    "        # List all available CUDA devices\n",
    "        for i in range(num_devices):\n",
    "            print(f\"Device {i}: {torch.cuda.get_device_name(i)}\")\n",
    "            \n",
    "        print()\n",
    "\n",
    "        if len(cuda_device_num) > 1:\n",
    "            # Use multiple GPUs with DataParallel if more than one GPU is available\n",
    "            device = torch.device(\"cuda\")\n",
    "            print(\"Using multiple GPUs\")\n",
    "            for i in range(num_devices):\n",
    "                print(f\"Device {i}: {torch.cuda.get_device_name(i)}\")\n",
    "        elif len(cuda_device_num) == 1:\n",
    "            # Use only one GPU if exactly one GPU is available\n",
    "            device = torch.device(f\"cuda:{cuda_device_num[0]}\")\n",
    "            print(f\"Using single GPU: Device {cuda_device_num[0]} -> {torch.cuda.get_device_name(cuda_device_num[0])}\")\n",
    "        else:\n",
    "            # Fallback to CPU if no GPUs are available\n",
    "            device = torch.device(\"cpu\")\n",
    "            print(\"No GPUs found, using CPU\")\n",
    "    else:\n",
    "        # Use CPU if CUDA is not available\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"CUDA not available, using CPU\")\n",
    "    \n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coco_train_test_split(in_dir, data_dir):\n",
    "    fn = in_dir.split(\"/\")[-1]\n",
    "    \n",
    "    if fn == None:\n",
    "        fn = in_dir.split(\"/\")[-2]\n",
    "  \n",
    "    # data_dir = os.getcwd() + \"/\" + fn + \"_split\"\n",
    "    \n",
    "    if not os.path.exists(data_dir):\n",
    "        os.mkdir(data_dir)\n",
    "\n",
    "        train_dir = data_dir + \"/train\"\n",
    "        os.mkdir(train_dir)\n",
    "        train_img_dir = train_dir + \"/images\"\n",
    "        os.mkdir(train_img_dir)\n",
    "\n",
    "        test_dir = data_dir + \"/test\"\n",
    "        os.mkdir(test_dir)\n",
    "        test_img_dir = test_dir + \"/images\"\n",
    "        os.mkdir(test_img_dir)\n",
    "\n",
    "        train_split = 0.8\n",
    "\n",
    "        f = open(in_dir + \"/result.json\")\n",
    "        coco_json = json.load(f)\n",
    "        f.close()\n",
    "\n",
    "        num_img = len(coco_json[\"images\"])\n",
    "\n",
    "        img_list = coco_json[\"images\"]\n",
    "        cat_list = coco_json[\"categories\"]\n",
    "        ann_list = coco_json[\"annotations\"]\n",
    "\n",
    "        train_num = math.floor(num_img * train_split)\n",
    "\n",
    "        train_img_list = img_list[0:train_num]\n",
    "        test_img_list = img_list[train_num:]\n",
    "\n",
    "        for each in train_img_list:\n",
    "            img_name = each[\"file_name\"].split(\"/\")[-1]\n",
    "            shutil.copy(in_dir + \"/images/\" + img_name, train_img_dir + \"/\" + img_name)\n",
    "\n",
    "        for each in test_img_list:\n",
    "            img_name = each[\"file_name\"].split(\"/\")[-1]\n",
    "            shutil.copy(in_dir + \"/images/\" + img_name, test_img_dir + \"/\" + img_name)\n",
    "\n",
    "        co_val = train_img_list[-1][\"id\"]\n",
    "\n",
    "        train_ann_list = []\n",
    "        test_ann_list = []\n",
    "\n",
    "        for each in ann_list:\n",
    "            if each[\"image_id\"] <= co_val:\n",
    "                train_ann_list.append(each)\n",
    "            else:\n",
    "                test_ann_list.append(each)\n",
    "\n",
    "        train_json = {\n",
    "            \"images\": train_img_list,\n",
    "            \"categories\": cat_list,\n",
    "            \"annotations\": train_ann_list\n",
    "        }\n",
    "\n",
    "        test_json = {\n",
    "            \"images\": test_img_list,\n",
    "            \"categories\": cat_list,\n",
    "            \"annotations\": test_ann_list\n",
    "        }\n",
    "\n",
    "        train_j_out = json.dumps(train_json, indent=4)\n",
    "        test_j_out = json.dumps(test_json, indent=4)\n",
    "\n",
    "        with open(train_dir + \"/result.json\", \"w\") as outfile:\n",
    "            outfile.write(train_j_out)\n",
    "        with open(test_dir + \"/result.json\", \"w\") as outfile:\n",
    "            outfile.write(test_j_out)\n",
    "            \n",
    "        print(\"creating \" + str(train_split) + \" train test split to path: \" + data_dir)\n",
    "        \n",
    "    else:\n",
    "        print(\"directory: \" + data_dir + \" already exists!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cust_coll(batch):\n",
    "\n",
    "    # Separate data and targets\n",
    "    batch = list(zip(*batch))\n",
    "\n",
    "    # Default collate for images\n",
    "    images = default_collate(batch[0])\n",
    "\n",
    "    # Targets are a list of dictionaries\n",
    "    targets = batch[1]\n",
    "\n",
    "    return images, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(num_classes, backbone, pretrained):\n",
    "    \n",
    "    ### OTHER WAY THAT WORKS\n",
    "    # model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretained=True)\n",
    "    # num_classes = 27+1\n",
    "    # in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    # model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    \n",
    "    # Load a pre-trained model for the backbone\n",
    "    backbone = resnet_fpn_backbone(backbone_name=backbone, pretrained=pretrained)\n",
    "    \n",
    "    # Create an instance of FasterRCNN with the FPN backbone\n",
    "    model = FasterRCNN(backbone, num_classes=num_classes)\n",
    "\n",
    "    # Replace the classifier head of the model with a new one for our number of classes\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupByImgId(res):\n",
    "\n",
    "    g_img_id = {}\n",
    "\n",
    "    # Iterate through each annotation in the data\n",
    "    for ann in res:\n",
    "        image_id = ann['image_id']\n",
    "\n",
    "        # If the image_id is not in the dictionary, add it with an empty list\n",
    "        if image_id not in g_img_id:\n",
    "            g_img_id[image_id] = []\n",
    "\n",
    "        # Append the current annotation to the list associated with the image_id\n",
    "        g_img_id[image_id].append(ann)\n",
    "    \n",
    "    return g_img_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_to_data_dict(json_obj, data_dir):\n",
    "    \n",
    "    data_dict_list = []\n",
    "    \n",
    "    grouped_anns = groupByImgId(json_obj)\n",
    "    keys = grouped_anns.keys()\n",
    "    \n",
    "    with open(os.path.join(data_dir, \"test/result.json\")) as f:\n",
    "        og_coco_obj = json.load(f)\n",
    "    imgs = og_coco_obj[\"images\"]\n",
    "    \n",
    "    ann_id = 0\n",
    "    \n",
    "    for i, img_id_res in enumerate(keys):\n",
    "        \n",
    "        fn = \"\"\n",
    "        for img in imgs:\n",
    "            if img_id_res == img[\"id\"]:\n",
    "                fn = os.path.join(data_dir, \"test\", \"images\", img[\"file_name\"][2:])\n",
    "                \n",
    "        ann_list = []\n",
    "        annotation = {}\n",
    "        \n",
    "        for j, ann in enumerate(grouped_anns[img_id_res]): \n",
    "    \n",
    "            # Constants for height and width\n",
    "            height = img_height\n",
    "            width = img_width\n",
    "\n",
    "            # Extract values from the input JSON\n",
    "            image_id_res= ann[\"image_id\"]\n",
    "            bbox = ann[\"bbox\"]\n",
    "\n",
    "            # Convert the bbox format [x1, y1, x2, y2] to [x, y, width, height]\n",
    "            x1, y1, x2, y2 = bbox\n",
    "            x, y, width_bb, height_bb = x1, y1, x2 - x1, y2 - y1\n",
    "            \n",
    "            # Create the output annotation dictionary\n",
    "            annotation = {\n",
    "                \"id\": ann_id,  # You can use image_id_res as the annotation ID or generate a unique ID\n",
    "                \"image_id\": image_id_res,\n",
    "                \"category_id\": ann[\"category_id\"],\n",
    "                \"bbox\": [x, y, width_bb, height_bb],\n",
    "                \"area\": width_bb * height_bb,  # Calculate the area (width * height)\n",
    "                \"iscrowd\": 0,  # Assuming not a crowd annotation\n",
    "                \"score\": ann[\"score\"]\n",
    "            }\n",
    "            \n",
    "            ann_list.append(annotation)\n",
    "            \n",
    "            ann_id = ann_id + 1\n",
    "\n",
    "        # Create the output data dictionary\n",
    "        data_dict = {\n",
    "            \"file_name\": fn,  # Assuming a filename based on image_id\n",
    "            \"height\": height,\n",
    "            \"width\": width,\n",
    "            \"annotations\": ann_list\n",
    "        }\n",
    "        \n",
    "        data_dict_list.append(data_dict)\n",
    "    \n",
    "    return data_dict_list\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Cuda Devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device\n",
    "device = set_device(cuda_device_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulating & Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating train and test set\n",
    "coco_train_test_split(in_dir, data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = CocoDetection(root=os.path.join(\"../../data/obj_det\", os.path.basename(in_dir),\"train/images\"), \n",
    "                          annFile=os.path.join(\"../../data/obj_det\", os.path.basename(in_dir),\"train/result.json\"), \n",
    "                          transform=transform)\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=shuffle, \n",
    "                           num_workers=num_workers, collate_fn=cust_coll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = CocoDetection(root=os.path.join(\"../../data/obj_det\", os.path.basename(in_dir),\"test/images\"), \n",
    "                         annFile=os.path.join(\"../../data/obj_det\", os.path.basename(in_dir),\"test/result.json\"), \n",
    "                         transform=transform)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=True, \n",
    "                         num_workers=num_workers, collate_fn=cust_coll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(num_classes, backbone, pretrained)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    start_time_epoch = time.time()  # Start time of the epoch\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "\n",
    "        images, targets = data\n",
    "        images = list(image.to(device) for image in images)\n",
    "\n",
    "        targets_cln = copy.deepcopy(targets)\n",
    "        for batch in targets_cln:\n",
    "            batch.pop('img_ids', None)\n",
    "\n",
    "        targets_cln = [{k: v.to(device) for k, v in t.items()} for t in targets_cln]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        loss_dict = model(images, targets_cln)\n",
    "\n",
    "        # The loss is the sum of all individual losses\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        print(f\"Iteration {i}, Loss: {losses.item()}, Time: {datetime.datetime.now()}\")\n",
    "\n",
    "        # Backward pass\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += losses.item()\n",
    "\n",
    "    epoch_duration = time.time() - start_time_epoch\n",
    "    \n",
    "    print(\"---\")\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader)}, Duration: {epoch_duration:.2f} seconds, Timestamp: {datetime.datetime.now()}\")\n",
    "    print(\"---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model to file\n",
    "pth_path = os.path.join(out_dir, \"./pth\")\n",
    "if not os.path.exists(pth_path):\n",
    "    os.makedirs(pth_path)\n",
    "torch.save(model, os.path.join(pth_path, \"model.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Load the COCO ground truth\n",
    "coco_path = os.path.join(\"../../data/obj_det\", os.path.basename(in_dir), \"test/result.json\")\n",
    "cocoGt = COCO(coco_path)\n",
    "\n",
    "img_ids = []\n",
    "with open(coco_path, \"r\") as f:\n",
    "    obj = json.load(f)\n",
    "for img in obj[\"images\"]:\n",
    "    img_ids.append(img[\"id\"])\n",
    "\n",
    "# Prepare for COCO evaluation\n",
    "results = []\n",
    "ind = 0\n",
    "\n",
    "# Start time of the evaluation\n",
    "start_time_eval = time.time()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, targets in test_loader:\n",
    "\n",
    "        images = list(img.to(device) for img in images)\n",
    "        outputs = model(images)\n",
    "\n",
    "        for i, output in enumerate(outputs):\n",
    "            print(f\"Evaluating image index: {ind}, Time: {datetime.datetime.now()}\")\n",
    "            img_ids = targets[i][\"img_ids\"]\n",
    "\n",
    "            for box, label, score, img_id in zip(output[\"boxes\"], output[\"labels\"], output[\"scores\"], img_ids):\n",
    "                box = box.cpu().numpy()\n",
    "                box = [float(n) for n in box]\n",
    "                score = float(score)\n",
    "                label = int(label)\n",
    "\n",
    "                res = {\n",
    "                    \"image_id\": img_id,\n",
    "                    \"category_id\": label,\n",
    "                    \"bbox\": [box[0], box[1], box[2] - box[0], box[3] - box[1]],\n",
    "                    \"score\": score\n",
    "                }\n",
    "                results.append(res)\n",
    "                \n",
    "            ind += 1\n",
    "\n",
    "eval_duration = time.time() - start_time_eval\n",
    "print(f\"Total evaluation time: {eval_duration:.2f} seconds, Timestamp: {datetime.datetime.now()}\")\n",
    "\n",
    "res_path = os.path.join(out_dir, \"results\")\n",
    "if not os.path.exists(res_path):\n",
    "    os.makedirs(res_path)\n",
    "    \n",
    "# Save the results in a file\n",
    "with open(os.path.join(res_path, \"results.json\"), \"w\") as f:\n",
    "    json.dump(results, f)\n",
    "\n",
    "print(f\"Results saved in {os.path.join(res_path, 'results.json')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantitative "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results into COCO data structure\n",
    "cocoDt = cocoGt.loadRes(os.path.join(res_path,\"results.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COCO evaluation\n",
    "cocoEval = COCOeval(cocoGt, cocoDt, 'bbox')\n",
    "cocoEval.params.imgIds = img_ids\n",
    "cocoEval.evaluate()\n",
    "cocoEval.accumulate()\n",
    "original_stdout = sys.stdout \n",
    "\n",
    "captured_output = io.StringIO()\n",
    "sys.stdout = captured_output\n",
    "cocoEval.summarize()\n",
    "sys.stdout = original_stdout\n",
    "summary_str = captured_output.getvalue()\n",
    "\n",
    "with open(os.path.join(res_path, \"scores.txt\"), 'w') as file:\n",
    "    file.write(summary_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qualitative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting results in data dict format\n",
    "data_dict_list = res_to_data_dict(results, data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to map category_ids to unique colors\n",
    "category_colors = {1: \"red\"}\n",
    "\n",
    "# Get unique category_ids\n",
    "unique_category_ids = set()\n",
    "for data_dict in data_dict_list:\n",
    "    for annotation in data_dict['annotations']:\n",
    "        unique_category_ids.add(annotation['category_id'])\n",
    "\n",
    "# Generate unique colors for each category\n",
    "for category_id in unique_category_ids:\n",
    "    color = tuple(np.random.randint(0, 256, 3).tolist())  # Generate a random color for each category\n",
    "    category_colors[category_id] = color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 = EOI\n",
    "category_labels = {\n",
    "    1: '1',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating output images directory\n",
    "img_out_path = os.path.join(out_dir, \"imgs\")\n",
    "if not os.path.exists(img_out_path ):\n",
    "    os.makedirs(img_out_path )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through data_dict_list and draw bounding boxes with category labels\n",
    "\n",
    "num_to_proc = min(len(data_dict_list), num_test_imgs_out)\n",
    "\n",
    "for data_dict in data_dict_list[0:num_to_proc]:\n",
    "    \n",
    "    print(data_dict)\n",
    "    image_path = data_dict['file_name']\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    for annotation in data_dict['annotations']:\n",
    "        bbox = annotation['bbox']\n",
    "        x, y, w, h = bbox\n",
    "        x, y, w, h = int(x), int(y), int(w), int(h)\n",
    "\n",
    "        category_id = annotation['category_id']\n",
    "        category_label = category_labels.get(category_id, 'Unknown')\n",
    "        category_color = category_colors.get(category_id, (0, 0, 255))  # Default to blue if not in mapping\n",
    "\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), category_color, 2)  # Draw the bounding box\n",
    "        cv2.putText(image, category_label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, category_color, 2)\n",
    "\n",
    "    # Save the image with bounding boxes and labels to the output directory\n",
    "    output_path = os.path.join(img_out_path, os.path.basename(image_path))\n",
    "    cv2.imwrite(output_path, image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_class_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
